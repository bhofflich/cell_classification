{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('/Volumes/Lab/Users/bhofflic/cell_classification/src/')\n",
    "import cell_display_lib as cdl\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from file_handling import wrapper\n",
    "\n",
    "scratch_file_root = '/Volumes/Scratch/Users/bhofflic/celltable_runs' # replace my name!\n",
    "corr_analysis_path = '/Volumes/Scratch/Users/bhofflic/cell_correlations/'\n",
    "\n",
    "pieces = [\n",
    "    # '2005-04-14-0', #9.8*\n",
    "    # '2005-04-26-1', #20.7*\n",
    "    '2005-07-07-2', #7.8*\n",
    "    # '2015-09-23-7', #40.6*\n",
    "    # '2016-02-17-1', #29.1*\n",
    "    # '2016-02-17-6', #28.0*\n",
    "    # '2016-02-17-8', #48.6*\n",
    "    # '2016-04-21-1', #33.8*\n",
    "    # '2017-03-15-1', #21.1*\n",
    "    # '2017-03-15-8', #12.3*\n",
    "    # '2017-08-14-4', #14.3*\n",
    "    # '2017-11-29-0', #33.0*\n",
    "    # '2018-03-01-0', #98.3-\n",
    "    # '2018-08-07-1', #26.1\n",
    "    # '2018-08-07-11',#8.5*\n",
    "    # '2018-08-07-2', #15.7*\n",
    "    # '2018-08-07-5', #22.2*\n",
    "    # '2018-08-07-9', #13.9*\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Welcome to the CellTable ~experience~\n",
      "~ \n",
      "~ Starting a fresh new CellTable\n",
      "~ Loading 1 pieces from /Volumes/Scratch/Users/bhofflic/celltable_runs: ['2005-07-07-2']\n",
      "*** timer  started\n",
      "Loading piece 2005-07-07-2\n",
      "~ Successfully loaded piece 2005-07-07-2\n",
      "*** elapsed 6s of 6s = 0.1m elapsed, of 0.1m estimated (1/1) (0.2 / sec)\n",
      "~ Processing labels (replace nan, update label encoder and unique names)\n",
      "Copying cell labels to units\n",
      "combined mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Done loading, time to analyze.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for piece_id in tqdm(pieces):\n",
    "    ct = cdl.CellTable()\n",
    "    ct.file_load_pieces(scratch_file_root, [piece_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_run, num_cells = None, 0\n",
    "cell_types_of_interest = ['ON parasol', 'OFF parasol', 'ON midget', 'OFF midget', 'ON smooth', 'OFF smooth', 'SBC']\n",
    "for run in ct.dataset_table['run_id'].unique():\n",
    "    valid_units = ct.unit_table.query('valid==True and run_id==@run')\n",
    "    ctoi = valid_units.query('label_manual_text in @cell_types_of_interest')\n",
    "    if len(ctoi) > num_cells:\n",
    "        max_run = run\n",
    "        num_cells = len(ctoi)\n",
    "run_id = max_run\n",
    "\n",
    "valid_units = ct.unit_table.query('valid==True and run_id==@run_id')\n",
    "tcs = np.array([tc.a for tc in valid_units['tc_all']])\n",
    "acfs = np.array([acf.a for acf in valid_units['acf']])\n",
    "labels = np.array([label for label in valid_units['label_manual_text']])\n",
    "distances = ct.dataset_table.query('run_id==@run_id')['rf_overlaps'][0].a\n",
    "overlaps = ct.dataset_table.query('run_id==@run_id')['rf_inner_products'][0].a\n",
    "cch_1ms = ct.dataset_table.query('run_id==@run_id')['cch_1ms'][0].a\n",
    "cch_10ms = ct.dataset_table.query('run_id==@run_id')['cch_10ms'][0].a\n",
    "uids = [uid for uid in ct.dataset_table.query('run_id==@run_id')['cch_ids'][0].a]\n",
    "eis = np.array([ei.a for ei in valid_units['ei']])\n",
    "spike_waveforms = np.array([sw.a for sw in valid_units['spike_waveform_smart']])\n",
    "spike_counts = np.array([sc for sc in valid_units['spike_count']])\n",
    "sizes = np.max(np.array([size.a for size in valid_units['rf_size_hull']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'piece_id': [piece_id for _ in range(len(uids))],\n",
    "    'run_id': [run_id for _ in range(len(uids))],\n",
    "    'unit_id': uids,\n",
    "    'tc': [wrapper(tc) for tc in tcs],\n",
    "    'acf': [wrapper(acf) for acf in acfs],\n",
    "    'label': labels,\n",
    "    'distances': [wrapper(distance) for distance in distances],\n",
    "    'overlaps': [wrapper(overlap) for overlap in overlaps],\n",
    "    'cch_1ms': [wrapper(cch) for cch in cch_1ms],\n",
    "    'cch_10ms': [wrapper(cch) for cch in cch_10ms],\n",
    "    'ei': [wrapper(ei) for ei in eis],\n",
    "    'spike_waveform': [wrapper(sw) for sw in spike_waveforms],\n",
    "    'spike_count': spike_counts,\n",
    "    'size': sizes,\n",
    "}\n",
    "dataframe = pd.DataFrame(data=data, index=uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_pickle(corr_analysis_path + 'gnn_data/' + piece_id + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhofflich-scpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
